{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "### Goal:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
    "But first, the dataset will be simplified to retain less features since our main goal is to build a simple web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression\n",
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# ========== NEW IMPORTS ========\n",
    "# Respect to notebook 02-Predicting-Survival-Titanic-Solution\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for the preprocessors\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# for imputation\n",
    "from feature_engine.imputation import (AddMissingIndicator, # for numerical var\n",
    "                                        MeanMedianImputer, # for numerical values\n",
    "                                        CategoricalImputer, # for rare and missing in cat var\n",
    "                                    )\n",
    "\n",
    "# for encoding categorical variables\n",
    "from feature_engine.encoding import (RareLabelEncoder, OneHotEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>135</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket      fare    cabin embarked boat body  \\\n",
       "0      29      0      0   24160  211.3375       B5        S    2    ?   \n",
       "1  0.9167      1      2  113781    151.55  C22 C26        S   11    ?   \n",
       "2       2      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "3      30      1      2  113781    151.55  C22 C26        S    ?  135   \n",
       "4      25      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl')\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace interrogation marks by NaN values\n",
    "\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['cabin'] = data['cabin'].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['title'] = data['name'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        int64\n",
       "survived      int64\n",
       "name         object\n",
       "sex          object\n",
       "age          object\n",
       "sibsp         int64\n",
       "parch         int64\n",
       "ticket       object\n",
       "fare         object\n",
       "cabin        object\n",
       "embarked     object\n",
       "boat         object\n",
       "body         object\n",
       "home.dest    object\n",
       "title        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical variables as floats\n",
    "\n",
    "data['fare'] = data['fare'].astype('float')\n",
    "data['age'] = data['age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>Master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex      age  sibsp  parch      fare cabin embarked  \\\n",
       "0       1         1  female  29.0000      0      0  211.3375    B5        S   \n",
       "1       1         1    male   0.9167      1      2  151.5500   C22        S   \n",
       "2       1         0  female   2.0000      1      2  151.5500   C22        S   \n",
       "3       1         0    male  30.0000      1      2  151.5500   C22        S   \n",
       "4       1         0  female  25.0000      1      2  151.5500   C22        S   \n",
       "\n",
       "    title  \n",
       "0    Miss  \n",
       "1  Master  \n",
       "2    Miss  \n",
       "3      Mr  \n",
       "4     Mrs  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['name','ticket', 'boat', 'body','home.dest'], axis=1, inplace=True)\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the dataset that we will used to build the web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data set\n",
    "\n",
    "# data.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin',\n",
       "       'embarked', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('./datasets/titanic.csv').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin the pipeline structure\n",
    "\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables to be used in the pipeline's transformers\n",
    "\n",
    "NUMERICAL_VARIABLES = ['age', 'fare']\n",
    "\n",
    "CATEGORICAL_VARIABLES = ['sex', 'cabin', 'embarked', 'title'] #['cabin', 'embarked'] # only cols with missing values\n",
    "\n",
    "CABIN = ['cabin'] # for first letter extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1047, 9), (262, 9))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('survived', axis=1),  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessors\n",
    "\n",
    "### Class to extract the letter from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractLetterTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Extract fist letter of variable\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "\n",
    "        self.variables = variables\n",
    "\n",
    "    def fit(self, X, y=None): # very important should have X and y otherwise you will have an error\n",
    "        return self        \n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for feature in self.variables:\n",
    "            X[feature] = X[feature].str[0]\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "- Impute categorical variables with string missing\n",
    "- Add a binary missing indicator to numerical variables with missing data\n",
    "- Fill NA in original numerical variable with the median\n",
    "- Extract first letter from cabin\n",
    "- Group rare Categories\n",
    "- Perform One hot encoding\n",
    "- Scale features with standard scaler\n",
    "- Fit a Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "titanic_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string 'missing'\n",
    "    ('categorical_imputation', CategoricalImputer(imputation_method='missing', variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "    # add missing indicator to numerical variables\n",
    "    ('missing_indicator', AddMissingIndicator(variables=NUMERICAL_VARIABLES)),\n",
    "\n",
    "    # impute numerical variables with the median\n",
    "    ('median_imputation', MeanMedianImputer(imputation_method='median', variables=NUMERICAL_VARIABLES)),\n",
    "\n",
    "\n",
    "    # Extract first letter from cabin\n",
    "    ('extract_letter', ExtractLetterTransformer(variables=CABIN)),\n",
    "\n",
    "    # == CATEGORICAL ENCODING ======\n",
    "    # remove categories present in less than 5% of the observations (0.05)\n",
    "    # group them in one category called 'Rare'\n",
    "    ('rare_label_encoder', RareLabelEncoder(tol=.05, n_categories=1, variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "\n",
    "    # encode categorical variables using one hot encoding into k-1 variables\n",
    "    ('categorical_encoder', OneHotEncoder(drop_last=True, variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "    # scale using standardization\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "    # logistic regression (use C=0.0005 and random_state=0)\n",
    "    ('Logit', LogisticRegression(C=.0005, random_state=0)),\n",
    "])\n",
    "\n",
    "# Show the pipeline\n",
    "#titanic_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('categorical_imputation',\n",
       "                 CategoricalImputer(variables=['sex', 'cabin', 'embarked',\n",
       "                                               'title'])),\n",
       "                ('missing_indicator',\n",
       "                 AddMissingIndicator(variables=['age', 'fare'])),\n",
       "                ('median_imputation',\n",
       "                 MeanMedianImputer(variables=['age', 'fare'])),\n",
       "                ('extract_letter',\n",
       "                 ExtractLetterTransformer(variables=['cabin'])),\n",
       "                ('rare_label_encoder',\n",
       "                 RareLabelEncoder(n_categories=1,\n",
       "                                  variables=['sex', 'cabin', 'embarked',\n",
       "                                             'title'])),\n",
       "                ('categorical_encoder',\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=['sex', 'cabin', 'embarked',\n",
       "                                          'title'])),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('Logit', LogisticRegression(C=0.0005, random_state=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the pipeline\n",
    "titanic_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance\n",
    "\n",
    "We will compute:\n",
    "- roc-auc\n",
    "- accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc-auc: 0.8450386398763523\n",
      "train accuracy: 0.7220630372492837\n",
      "\n",
      "test roc-auc: 0.8354629629629629\n",
      "test accuracy: 0.7137404580152672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train set\n",
    "class_ = titanic_pipe.predict(X_train)\n",
    "pred_prob = titanic_pipe.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred_prob)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = titanic_pipe.predict(X_test)\n",
    "pred = titanic_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pclass     sex   age sibsp parch  fare cabin embarked title\n",
       "0      2  female  21.0     0     1  21.0   NaN        S  Miss"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input shape:\n",
    "Xinput = X_test.iloc[1,:].values\n",
    "pred_df = pd.DataFrame(Xinput).T\n",
    "pred_df.columns = X_test.columns\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = X_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pclass     sex   age sibsp parch  fare cabin embarked title\n",
       "0      2  female  21.0     0     1  21.0   NaN        S  Miss"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xinput.reshape(1,-1), columns=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pipe.predict(pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and create the ppipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Pipeline :  titanic_classification_v_0.0.0.pkl\n"
     ]
    }
   ],
   "source": [
    "# pipeline test\n",
    "!python train_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last model saved for prediction:  ./trained_models/titanic_classification_v_0.0.0.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "a = !python predict.py\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install streamlit and create the requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.2.0-py2.py3-none-any.whl (9.1 MB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (8.4.0)\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (1.3.4)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-0.9.tar.gz (178 kB)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (1.20.3)\n",
      "Collecting altair>=3.2.0\n",
      "  Using cached altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "Collecting protobuf!=3.11,>=3.6.0\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting base58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 1.2.1 requires wrapt>=1.10.10, which is not installed.\n",
      "aiohttp 3.7.4 requires chardet<4.0,>=2.0, but you have chardet 4.0.0 which is incompatible.\n",
      "aiobotocore 1.2.1 requires botocore<1.19.53,>=1.19.52, but you have botocore 1.19.63 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "Collecting click<8.0,>=7.0\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (21.0)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-6.0.1-cp38-cp38-win_amd64.whl (15.5 MB)\n",
      "Collecting validators\n",
      "  Using cached validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: toml in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Collecting cachetools>=4.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
      "Requirement already satisfied: attrs in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (21.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (2.26.0)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.6-py3-none-win_amd64.whl (76 kB)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-4.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.11.2-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2021.3)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (6.4.1)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (7.6.5)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.1.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.0.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.29.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.4.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (58.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.20)\n",
      "Requirement already satisfied: pygments in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.10.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.2.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.5.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (228)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.4.5)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.4)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.1.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.1.0)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.20)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.0.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.10)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from packaging->streamlit) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->streamlit) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->streamlit) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->streamlit) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->streamlit) (1.25.11)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2021.5-py2.py3-none-any.whl (339 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-win_amd64.whl (38 kB)\n",
      "Building wheels for collected packages: pympler, blinker\n",
      "  Building wheel for pympler (setup.py): started\n",
      "  Building wheel for pympler (setup.py): finished with status 'done'\n",
      "  Created wheel for pympler: filename=Pympler-0.9-py3-none-any.whl size=164824 sha256=2b5a7b44631225d5f2f3e2b7f072e4ff36758c1681e95aa5e0dbd55bb00e2c77\n",
      "  Stored in directory: c:\\users\\sebas\\appdata\\local\\pip\\cache\\wheels\\24\\6f\\0b\\da9f81234859a8741aaea3afcc6ae2daf0efb67e7ff2d3686c\n",
      "  Building wheel for blinker (setup.py): started\n",
      "  Building wheel for blinker (setup.py): finished with status 'done'\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=40f3e3828e3e3c412d59025cf2e8c354155e5d624939350d10d22044f1fdd510\n",
      "  Stored in directory: c:\\users\\sebas\\appdata\\local\\pip\\cache\\wheels\\b7\\a5\\68\\fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4\n",
      "Successfully built pympler blinker\n",
      "Installing collected packages: tzdata, smmap, backports.zoneinfo, typing-extensions, toolz, pytz-deprecation-shim, gitdb, watchdog, validators, tzlocal, pympler, pydeck, pyarrow, protobuf, gitpython, click, cachetools, blinker, base58, astor, altair, streamlit\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.3\n",
      "    Uninstalling click-8.0.3:\n",
      "      Successfully uninstalled click-8.0.3\n",
      "Successfully installed altair-4.1.0 astor-0.8.1 backports.zoneinfo-0.2.1 base58-2.1.1 blinker-1.4 cachetools-4.2.4 click-7.1.2 gitdb-4.0.9 gitpython-3.1.24 protobuf-3.19.1 pyarrow-6.0.1 pydeck-0.7.1 pympler-0.9 pytz-deprecation-shim-0.1.0.post0 smmap-5.0.0 streamlit-1.2.0 toolz-0.11.2 typing-extensions-4.0.1 tzdata-2021.5 tzlocal-4.1 validators-0.18.2 watchdog-2.1.6\n"
     ]
    }
   ],
   "source": [
    "# installation of streamlit + pipreqs\n",
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
      "Collecting yarg\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from yarg->pipreqs) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebas\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (2021.10.8)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13724 sha256=0b408031f943c72b5ed0b4605c8adeb0201e775e14ef81497cf8dffe56391d05\n",
      "  Stored in directory: c:\\users\\sebas\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: yarg, docopt, pipreqs\n",
      "Successfully installed docopt-0.6.2 pipreqs-0.4.11 yarg-0.1.9\n"
     ]
    }
   ],
   "source": [
    "# to save libraries\n",
    "!pip install pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully saved requirements file in ./requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# write the requirement file\n",
    "#import pipreqs\n",
    "!pipreqs ./"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5108ef035adae81b438fd63e49a046e9c60a4d7d60a830aa9560d8422b46a796"
  },
  "kernelspec": {
   "display_name": "feml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
